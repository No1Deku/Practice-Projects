{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "17ae4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb as db\n",
    "import skimpy as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "cf42c880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Issues Faced \\nLoading Dataset (Unicode Error)\\nData Capture Error\\n(Values stored in Customer_ID)\\n'"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Issues Faced \n",
    "Loading Dataset (Unicode Error)\n",
    "Data Capture Error\n",
    "(Values stored in Customer_ID)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ffba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"E:\\\\Projects 25\\\\Student-Records\\\\Unclean_Dataset_1.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f25655",
   "metadata": {},
   "source": [
    "### Normalize Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "8a67dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [x.strip().lower() for x in data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8db90b",
   "metadata": {},
   "source": [
    "To ensure consistency and avoid issues caused by extra spaces or inconsistent casing in column headers, we normalize all column names by:\n",
    "- **Stripping** leading and trailing spaces\n",
    "- **Converting** all names to lowercase\n",
    "\n",
    "This makes it easier to work with the dataset programmatically, as column names become predictable and uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c635317",
   "metadata": {},
   "source": [
    "### Preview the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838250d",
   "metadata": {},
   "source": [
    "After normalizing the column names, it’s important to inspect the first few rows of the dataset.  \n",
    "Using `.head()` provides a quick snapshot of the structure, allowing us to:\n",
    "\n",
    "- Verify that column normalization was applied correctly  \n",
    "- Understand the data types and sample values  \n",
    "- Identify potential data quality issues (e.g., missing values, formatting inconsistencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8ada3",
   "metadata": {},
   "source": [
    "Problem 1 \n",
    "Data is trapped in the Student_ID column \n",
    "Solution \n",
    "Use the split_part function from sqllite to split the values across the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "d875396d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['student_id', 'first_name', 'last_name', 'age', 'gender', 'course',\n",
       "       'enrollment_date', 'total_payments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c5766",
   "metadata": {},
   "source": [
    "### Parse DataFrame into DuckDB for SQL Transformations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b76880",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = db.connect()\n",
    "con.execute(\"CREATE OR REPLACE TABLE df AS SELECT * FROM data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b1b7f",
   "metadata": {},
   "source": [
    "To leverage the power of SQL for data cleaning and transformation, we load the Pandas DataFrame into a **DuckDB in-memory table**.  \n",
    "This allows us to:  \n",
    "\n",
    "- Use **SQL queries** directly on the DataFrame  \n",
    "- Simplify complex transformations with SQL syntax  \n",
    "- Maintain a reproducible and efficient data pipeline  \n",
    "\n",
    "The following command creates (or replaces) a table named `df` inside DuckDB, containing all rows from the Pandas DataFrame `data`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8778ae",
   "metadata": {},
   "source": [
    "### Preview the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "28eb28a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>course</th>\n",
       "      <th>enrollment_date</th>\n",
       "      <th>total_payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101        | John       | Smith     | 22  | M ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102        | Emily      | Johnson   | 24  | F ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103        | Michael    | Williams  | 21  | M ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104        | Sarah      | Brown     | 23  | F ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105        | David      | Davis     | 20  | M ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>232        | Amina      | Adekunle    | 21  | ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>234       | Ibrahim    | Okafor      | 22  | M...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>235        | Zainab     | Abiodun     | 23  | ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>236        | Nasiru     | Adebayo     | 24  | ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>237       | Aisha      | Okonkwo     | 25  | F...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            student_id first_name last_name  \\\n",
       "0    101        | John       | Smith     | 22  | M ...       None      None   \n",
       "1    102        | Emily      | Johnson   | 24  | F ...       None      None   \n",
       "2    103        | Michael    | Williams  | 21  | M ...       None      None   \n",
       "3    104        | Sarah      | Brown     | 23  | F ...       None      None   \n",
       "4    105        | David      | Davis     | 20  | M ...       None      None   \n",
       "..                                                 ...        ...       ...   \n",
       "131  232        | Amina      | Adekunle    | 21  | ...       None      None   \n",
       "132  234       | Ibrahim    | Okafor      | 22  | M...       None      None   \n",
       "133  235        | Zainab     | Abiodun     | 23  | ...       None      None   \n",
       "134  236        | Nasiru     | Adebayo     | 24  | ...       None      None   \n",
       "135  237       | Aisha      | Okonkwo     | 25  | F...       None      None   \n",
       "\n",
       "      age gender course enrollment_date total_payments  \n",
       "0    None   None   None            None           None  \n",
       "1    None   None   None            None           None  \n",
       "2    None   None   None            None           None  \n",
       "3    None   None   None            None           None  \n",
       "4    None   None   None            None           None  \n",
       "..    ...    ...    ...             ...            ...  \n",
       "131  None   None   None            None           None  \n",
       "132  None   None   None            None           None  \n",
       "133  None   None   None            None           None  \n",
       "134  None   None   None            None           None  \n",
       "135  None   None   None            None           None  \n",
       "\n",
       "[136 rows x 8 columns]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"Select * from df\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c92f8",
   "metadata": {},
   "source": [
    "After normalizing the column names, it’s important to inspect the first few rows of the dataset.  \n",
    "Using `SQL Based Logic` provides a quick snapshot of the structure, allowing us to:\n",
    "\n",
    "- Verify that column normalization was applied correctly  \n",
    "- Understand the data types and sample values  \n",
    "- Identify potential data quality issues (e.g., missing values, formatting inconsistencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572f51f",
   "metadata": {},
   "source": [
    "### Transformation 1: Extracting and Populating Data from `student_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "5903be10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "UPDATE df\n",
    "SET\n",
    "    student_id = SPLIT_PART(student_id, '|', 1),\n",
    "    first_name = CASE \n",
    "                    WHEN first_name IS NULL AND SPLIT_PART(student_id, '|', 2) IS NOT NULL \n",
    "                    THEN SPLIT_PART(student_id, '|', 2)\n",
    "                    ELSE first_name\n",
    "                 END,\n",
    "    last_name = CASE \n",
    "                    WHEN last_name IS NULL AND SPLIT_PART(student_id, '|', 3) IS NOT NULL \n",
    "                    THEN SPLIT_PART(student_id, '|', 3)\n",
    "                    ELSE last_name\n",
    "                 END,\n",
    "    age = CASE \n",
    "             WHEN age IS NULL AND SPLIT_PART(student_id, '|', 4) IS NOT NULL \n",
    "             THEN SPLIT_PART(student_id, '|', 4)\n",
    "             ELSE age\n",
    "          END,\n",
    "    gender = CASE \n",
    "                WHEN gender IS NULL AND SPLIT_PART(student_id, '|', 5) IS NOT NULL \n",
    "                THEN SPLIT_PART(student_id, '|', 5)\n",
    "                ELSE gender\n",
    "             END,\n",
    "    course = CASE \n",
    "                WHEN course IS NULL AND SPLIT_PART(student_id, '|', 6) IS NOT NULL \n",
    "                THEN SPLIT_PART(student_id, '|', 6)\n",
    "                ELSE course\n",
    "             END,\n",
    "    enrollment_date = CASE \n",
    "                        WHEN enrollment_date IS NULL AND SPLIT_PART(student_id, '|', 7) IS NOT NULL \n",
    "                        THEN SPLIT_PART(student_id, '|', 7)\n",
    "                        ELSE enrollment_date\n",
    "                     END,\n",
    "    total_payments = CASE \n",
    "                        WHEN total_payments IS NULL AND SPLIT_PART(student_id, '|', 8) IS NOT NULL \n",
    "                        THEN SPLIT_PART(student_id, '|', 8)\n",
    "                        ELSE total_payments\n",
    "                     END\n",
    "WHERE \n",
    "    student_id IS NOT NULL\n",
    "    AND student_id <> ''  -- Use <> '' to check for non-empty string instead of LENGTH\n",
    "    AND (\n",
    "        first_name IS NULL OR last_name IS NULL OR age IS NULL\n",
    "        OR gender IS NULL OR course IS NULL OR enrollment_date IS NULL \n",
    "        OR total_payments IS NULL\n",
    "    )\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b7e54e",
   "metadata": {},
   "source": [
    "In the raw dataset, multiple attributes (e.g., name, age, gender, course, enrollment date, payments) were **embedded inside the `student_id` column** using the `|` delimiter.  \n",
    "This design caused issues such as:  \n",
    "\n",
    "- Missing values in key columns (`first_name`, `last_name`, `age`, etc.)  \n",
    "- Difficulty in performing queries or transformations  \n",
    "- Poor normalization and data readability  \n",
    "\n",
    "To resolve this, we applied an **SQL transformation in DuckDB** that:  \n",
    "1. Splits the `student_id` column using `SPLIT_PART` based on the `|` delimiter.  \n",
    "2. Populates missing fields (`first_name`, `last_name`, `age`, `gender`, `course`, `enrollment_date`, `total_payments`) with the corresponding extracted values.  \n",
    "3. Cleans the `student_id` column to only keep the unique identifier (the first split part).  \n",
    "\n",
    "This ensures the dataset is structured properly and avoids redundancy in storing values inside a single column.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd24b19",
   "metadata": {},
   "source": [
    "### Transformation 2: Standardizing Missing Enrollment Dates  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "5d8d0233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "UPDATE df\n",
    "SET enrollment_date = NULL\n",
    "WHERE enrollment_date = 'NA';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324f390d",
   "metadata": {},
   "source": [
    "During inspection, we noticed that the `enrollment_date` column contained the string `\"NA\"` instead of proper null values.  \n",
    "This creates problems because:  \n",
    "\n",
    "- `\"NA\"` is treated as a **string**, not a missing value  \n",
    "- It prevents correct **date parsing and transformations**  \n",
    "- It can lead to inaccurate results during analysis (e.g., when filtering by date ranges)  \n",
    "\n",
    "To address this, we replaced all `\"NA\"` values in `enrollment_date` with **SQL `NULL`**, ensuring missing values are consistently represented.  \n",
    "This standardization makes future transformations (such as casting to `DATE` or aggregating by enrollment period) more effective and reliable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27035c",
   "metadata": {},
   "source": [
    "### Standardize `gender` Casing and Trim Whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee1fa7",
   "metadata": {},
   "source": [
    "In the dataset, we observed issues where:  \n",
    "- `gender` and `age` were sometimes **interchanged**  \n",
    "- `gender` contained both **age and gender** (e.g., `\"M|23\"`)  \n",
    "- Inconsistent casing (`male`, `Female`, `f`, `M`, etc.)  \n",
    "\n",
    "As a first step, we standardized the `gender` column by:  \n",
    "- Removing extra whitespace  \n",
    "- Converting all values to uppercase  \n",
    "\n",
    "This ensures uniformity before handling more complex issues such as swapped or combined values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372f874",
   "metadata": {},
   "source": [
    "### Transformation 4: Trimming Spaces in `course`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "f6f24920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "UPDATE df\n",
    "SET gender = UPPER(gender)\n",
    "WHERE gender IS NOT NULL;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "3db2d6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cyber Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Machine Learnin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Web Developmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Web Developmet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Web Develpment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              course\n",
       "0                   \n",
       "1                  4\n",
       "2     Cyber Security\n",
       "3      Data Analysis\n",
       "4     Data Analytics\n",
       "5       Data Science\n",
       "6    Machine Learnin\n",
       "7   Machine Learning\n",
       "8     Web Developmen\n",
       "9    Web Development\n",
       "10    Web Developmet\n",
       "11    Web Develpment\n",
       "12              None"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.query(\"Select distinct course from df order by course asc\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9725130",
   "metadata": {},
   "source": [
    "### Transformation 4: Cleaning and Standardizing `course`  \n",
    "\n",
    "During inspection, we identified inconsistencies in the `course` column such as:  \n",
    "- Leading or trailing spaces (`\"Data Science \"` vs `\"Data Science\"`)  \n",
    "- Slight variations in spelling or truncation (`\"Machine Learning\"` vs `\"Machine Learnin\"`)  \n",
    "\n",
    "These inconsistencies reduce data quality and can cause issues during analysis, such as:  \n",
    "- Duplicate categories when grouping by course  \n",
    "- Difficulty in filtering or joining with reference data  \n",
    "\n",
    "As a first step, we removed leading and trailing spaces using the `TRIM()` function.  \n",
    "This prepares the column for deeper standardization in later steps, such as correcting misspellings and mapping variations to a canonical set of course names.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "4b43fce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"Update df set course = trim(course)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e2d8c6",
   "metadata": {},
   "source": [
    "### Transformation 5: Identifying and Resolving Spelling Inconsistencies in `course`  \n",
    "\n",
    "After trimming spaces, we still observed **spelling inconsistencies and variations** in the `course` column.  \n",
    "Examples include:  \n",
    "- `\"Machine Learnin\"` vs `\"Machine Learning\"`  \n",
    "- Variations of `\"Web Development\"` (e.g., `\"Web Develpment\"`, `\"Web Developmen\"`, `\"Web Developmet\"`)  \n",
    "- Overlaps between `\"Data Analysis\"` and `\"Data Analytics\"`  \n",
    "\n",
    "Such inconsistencies create fragmented categories, making it difficult to analyze course enrollment accurately.  \n",
    "\n",
    "To address this, we standardized the values by:  \n",
    "- Replacing empty strings (`''`) with `NULL`  \n",
    "- Mapping common misspellings and variations to a canonical label  \n",
    "- Ensuring consistency across related course names  \n",
    "\n",
    "This transformation improves **data quality** and ensures that groupings and aggregations on `course` will be meaningful.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "68a2509e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"UPDATE df\n",
    "SET course = CASE \n",
    "                WHEN course = '' THEN NULL\n",
    "                WHEN course IN ('Machine Learnin', 'Machine Learning') THEN 'Machine Learning'\n",
    "                WHEN course LIKE 'Web Develpment%' OR course LIKE 'Web Developmen%' OR course LIKE 'Web Development%' OR course LIKE 'Web Developmet%' THEN 'Web Development'\n",
    "                WHEN course LIKE 'Data Analysis%' OR course = 'Data Analytics' THEN 'Data Analytics'\n",
    "                ELSE course\n",
    "             END\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f88a0",
   "metadata": {},
   "source": [
    "### Transformation 6: Handling Invalid `student_id` Entries  \n",
    "\n",
    "During data profiling, we discovered instances where the `student_id` column incorrectly contained the **student's first name** instead of a proper identifier.  \n",
    "These cases indicate missing or invalid student IDs and could cause issues in:  \n",
    "- Uniquely identifying students  \n",
    "- Joining with other datasets  \n",
    "- Aggregations and analysis  \n",
    "\n",
    "To address this, we replaced these invalid entries with the placeholder `'Unknown'`, making it clear that the student ID is missing or incorrect.  \n",
    "This approach preserves data integrity while allowing further transformations and analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "d9a4a686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "UPDATE df\n",
    "SET student_id = 'Unknown'\n",
    "WHERE student_id = first_name;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c8e5ae",
   "metadata": {},
   "source": [
    "### Transformation 7: Adding `currency` Column  \n",
    "\n",
    "The `total_payments` column contains **varying currencies**, which can cause confusion when analyzing or aggregating payment data.  \n",
    "To handle this, we added a new column called `currency` to explicitly capture the type of currency for each payment.  \n",
    "\n",
    "This prepares the dataset for:  \n",
    "- Standardizing or converting amounts into a single currency  \n",
    "- Performing accurate financial analyses  \n",
    "- Avoiding misinterpretation of payment values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "db0932c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"ALTER Table df add column currency varchar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e84af4",
   "metadata": {},
   "source": [
    "### Transformation 8: Classifying Payment Currency  \n",
    "\n",
    "The `total_payments` column contains various currency symbols (e.g., `$`, `£`) and ambiguous entries (`?`), which makes financial analysis inconsistent.  \n",
    "\n",
    "To improve clarity and standardize the data, we classified the currency type by inspecting the `total_payments` values:  \n",
    "- `$` → `'USD'`  \n",
    "- `£` → `'Euro'`  \n",
    "- `?` or unmatched → `NULL`  \n",
    "\n",
    "This transformation ensures that each payment has a clearly identified currency, enabling accurate aggregations, conversions, and reporting.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "512a636c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "UPDATE df\n",
    "SET currency = CASE\n",
    "    WHEN total_payments LIKE '%$%' THEN 'USD'    -- If total_payments starts with '$', set currency to 'USD'\n",
    "    WHEN total_payments LIKE '%£%' THEN 'Euro'   -- If total_payments starts with '£', set currency to 'Euro'\n",
    "    WHEN total_payments LIKE  '%?%' THEN NULL         -- If total_payments is '?', set currency to NULL\n",
    "    ELSE NULL                                   -- If no match, set currency to NULL\n",
    "END\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6a2b4",
   "metadata": {},
   "source": [
    "### Transformation 9: Cleaning `age` Column  \n",
    "\n",
    "During data inspection, we found that some entries in the `age` column contained the `'*'` character, which can occur due to formatting errors or data entry issues.  \n",
    "\n",
    "To ensure that `age` values are numeric and consistent:  \n",
    "- We replaced all `'*'` characters with an empty string (`''`)  \n",
    "- This prepares the column for type conversion and further analysis  \n",
    "\n",
    "Cleaning these anomalies is crucial for accurate age-related calculations and validation.  \n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "197f497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"UPDATE df SET age = REPLACE(age, '*', '')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02caff",
   "metadata": {},
   "source": [
    "### Transformation 10: Converting Empty `age` Values to NULL  \n",
    "\n",
    "After removing invalid characters (like `'*'`), some entries in the `age` column were left as empty strings (`''`).  \n",
    "Empty strings do not behave like proper missing values in SQL and can interfere with:  \n",
    "- Aggregations and calculations  \n",
    "- Filtering or grouping by age  \n",
    "- Data quality checks  \n",
    "\n",
    "To address this, we replaced all empty string entries in `age` with `NULL`.  \n",
    "This ensures that missing ages are properly recognized and handled in later transformations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "f04520aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"Update df set age = NULL where age = ''   \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d15f6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526b3697",
   "metadata": {},
   "source": [
    "### Transformation 11: Resolving Complex Issues in `age` and `gender`  \n",
    "\n",
    "During data cleaning, we observed several complex inconsistencies in the `age` and `gender` columns:  \n",
    "- `age` and `gender` values were sometimes **swapped** (e.g., age = `'M'` and gender = actual age).  \n",
    "- `gender` occasionally contained **both age and gender** in one string (e.g., `'M23'`).  \n",
    "\n",
    "To resolve these issues, we applied a **long `CASE` statement**:  \n",
    "1. **Swapped values:** If `age` contains `'M'` or `'F'` and `gender` does not, we swap the values to correct the assignment.  \n",
    "2. **Split combined values:** If `age` is `NULL` and `gender` contains more than one character, we:  \n",
    "   - Set `age` = last two characters of `gender`  \n",
    "   - Set `gender` = first character of `gender`  \n",
    "\n",
    "This transformation ensures that both `age` and `gender` are separated, correctly assigned, and ready for accurate analysis and further transformations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "fccd25d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x2285ebfcbf0>"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"UPDATE df\n",
    "SET\n",
    "    age = CASE\n",
    "        -- Condition 1: When age is 'M' or 'F', and gender is not 'M' or 'F', swap the values\n",
    "        WHEN age IN ('M', 'F') AND gender NOT IN ('M', 'F') THEN gender\n",
    "        \n",
    "        -- Condition 2: When age is NULL and gender length > 1, set age = right(gender, 2) and gender = left(gender, 1)\n",
    "        WHEN age IS NULL AND LENGTH(gender) > 1 THEN RIGHT(gender, 2)\n",
    "        \n",
    "        ELSE age\n",
    "    END,\n",
    "    \n",
    "    gender = CASE\n",
    "        -- Condition 1: When age is 'M' or 'F', and gender is not 'M' or 'F', swap the values\n",
    "        WHEN age IN ('M', 'F') AND gender NOT IN ('M', 'F') THEN age\n",
    "        \n",
    "        -- Condition 2: When age is NULL and gender length > 1, set age = right(gender, 2) and gender = left(gender, 1)\n",
    "        WHEN age IS NULL AND LENGTH(gender) > 1 THEN LEFT(gender, 1)\n",
    "        \n",
    "        ELSE gender\n",
    "    END\n",
    "WHERE age IS NOT NULL OR gender IS NOT NULL;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb668d83",
   "metadata": {},
   "source": [
    "### Transformation 12: Standardizing `enrollment_date` Format  \n",
    "\n",
    "The `enrollment_date` column contained inconsistent date formats, including:  \n",
    "- `YYYY-MM-DD`  \n",
    "- Other unspecified or irregular formats  \n",
    "\n",
    "Inconsistent date formats can cause:  \n",
    "- Errors in date-based calculations  \n",
    "- Difficulties in filtering or grouping by month/year  \n",
    "- Issues with downstream transformations or visualizations  \n",
    "\n",
    "To resolve this, we implemented a logic to:  \n",
    "1. Detect dates in the `YYYY-MM-DD` pattern.  \n",
    "2. Reformat these dates to the standard `DD-MM-YYYY` format using `STRPTIME` and `STRFTIME`.  \n",
    "3. Keep other formats as-is for manual inspection or later correction.  \n",
    "\n",
    "This ensures that all recognized dates follow a consistent format, improving data reliability and analysis readiness.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "abba88fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollment_date</th>\n",
       "      <th>year</th>\n",
       "      <th>Format_Check</th>\n",
       "      <th>Reformatted_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>2022</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>2022-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>2022</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>2022-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-25</td>\n",
       "      <td>2022</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>2022-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>2021</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>2021-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2022-08-12</td>\n",
       "      <td>2022</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>2022-08-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>2022</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>2022-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>2022</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>2022-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>2022</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>2022-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>Other Format</td>\n",
       "      <td>2023-01-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       enrollment_date   year  Format_Check   Reformatted_Date\n",
       "0     2022-05-15         2022  Other Format   2022-05-15      \n",
       "1     2022-03-18         2022  Other Format   2022-03-18      \n",
       "2     2022-06-25         2022  Other Format   2022-06-25      \n",
       "3                 None   None  Other Format               None\n",
       "4     2021-09-10         2021  Other Format   2021-09-10      \n",
       "..                 ...    ...           ...                ...\n",
       "131   2022-08-12         2022  Other Format   2022-08-12      \n",
       "132   2022-02-03         2022  Other Format   2022-02-03      \n",
       "133   2022-07-21         2022  Other Format   2022-07-21      \n",
       "134   2022-05-09         2022  Other Format   2022-05-09      \n",
       "135   2023-01-15         2023  Other Format   2023-01-15      \n",
       "\n",
       "[136 rows x 4 columns]"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"WITH CTE AS (\n",
    "    SELECT * FROM df\n",
    ")\n",
    "SELECT \n",
    "    enrollment_date,\n",
    "    SPLIT_PART(enrollment_date, '-', 1) AS year,\n",
    "    CASE \n",
    "        -- Check if the first part of the date is a 4-digit year starting with '20'\n",
    "        WHEN SPLIT_PART(enrollment_date, '-', 1) LIKE '20__' \n",
    "             AND LENGTH(SPLIT_PART(enrollment_date, '-', 1)) = 4\n",
    "             AND SPLIT_PART(enrollment_date, '-', 2) IS NOT NULL\n",
    "             AND SPLIT_PART(enrollment_date, '-', 3) IS NOT NULL\n",
    "            THEN 'Year-Month-Day'  -- Format: YYYY-MM-DD\n",
    "        ELSE 'Other Format'  -- Any other format\n",
    "    END AS Format_Check,\n",
    "    \n",
    "    -- Reformat the date to DD-MM-YYYY if it matches the YYYY-MM-DD pattern\n",
    "    CASE \n",
    "        WHEN enrollment_date LIKE '20__-%' THEN \n",
    "            STRFTIME(STRPTIME(TRIM(enrollment_date), '%Y-%m-%d'), '%d-%m-%Y')\n",
    "        ELSE  enrollment_date-- Keep it as-is if it doesn't match\n",
    "    END AS Reformatted_Date\n",
    "\n",
    "FROM CTE;\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e0265",
   "metadata": {},
   "source": [
    "### Final Step: Save Cleaned Dataset  \n",
    "\n",
    "After performing all data cleaning and transformations, we save the final dataset to a CSV file for:  \n",
    "- Reproducibility and sharing  \n",
    "- Further analysis or reporting  \n",
    "- Ensuring the cleaned version is preserved separate from raw data  \n",
    "\n",
    "The cleaned dataset will be exported to the project folder:\n",
    "\n",
    "``E:\\Projects 25\\Student-Records``  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c37a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the cleaned data from DuckDB into a Pandas DataFrame\n",
    "cleaned_df = con.execute(\"SELECT * FROM df\").df()\n",
    "\n",
    "# Save the cleaned DataFrame to CSV in the project folder\n",
    "output_path = r\"E:\\Projects 25\\Student-Records\\cleaned_student_records.csv\"\n",
    "cleaned_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset successfully saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
